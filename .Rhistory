best_fit = best,
df_model = best_df,
AICc = best_aicc,
dAICc = best_delta,
AICcw = best_weight,
df_LRT = dflrt,
loglik = loglik,
lratio = lratio,
pvalue = pvalue
)
# Multiple comparisons
if (posthoc) {
# If GLS is the best fit...
if (best == 2) {
# Perform multiple comparisons using Wilcoxon tests
posthoc_test <- 2
group_names <- levels(data[, grouping])
# For each comparison of habitats...
posthoc_p <- sapply(seq_len(length(group_names) - 1), function(i) {
sapply(seq(i + 1, length(group_names)), function(j) {
# Perform a Wilcoxon test
pval <- wilcox.test(data[data[grouping] == group_names[j], variable], data[data[grouping] == group_names[i], variable])$p.value
names(pval) <- paste0(group_names[j], "-", group_names[i])
return (pval)
})
}) %>% unlist()
} else {
# Otherwise perform standard posthoc Tukey's HSD test
posthoc_test <- 1
posthoc_p <- TukeyHSD(aov(X ~ group, data))$group
posthoc_p <- posthoc_p[, "p adj"]
}
out <- c(out, posthoc_test = posthoc_test, posthoc_p = posthoc_p)
}
return (out)
}))
})))
if (univariate) {
# Package the output nicely
anovadata <- data.frame(
rep(names(data), each = length(variables)),
variable = rep(variables, length(data)),
anovadata
)
colnames(anovadata)[1] <- nesting
#anovadata <- anovadata %>% mutate(best_fit = factor(best_fit))
if (posthoc) anovadata <- anovadata %>% mutate(posthoc_test = factor(posthoc_test))
levels(anovadata$best) <- c("OLS", "GLS")
if (posthoc) levels(anovadata$posthoc_test) <- c("Tukey", "Wilcoxon")
}
if (add_signif) anovadata <- anovadata %>% add_signif()
return (anovadata)
}
nanova(data, variables, grouping = "habitat", nesting = "island",
univariate = TRUE, parametric = TRUE, random = "site")
#' Nested ANOVA
#'
#' Performs (M)ANOVAs for multiple variables across different subsets of the data. Models fitted with OLS and GLS (allowing one independent residual variance per group) are compared with AIC and the best-fitting model is retained. Multiple post-hoc comparisons can be performed too.
#'
#' @param data A data frame
#' @param variables The variables to analyze
#' @param nesting The name of the nesting factor
#' @param grouping The name of the grouping factor
#' @param posthoc Whether to perform post-hoc tests
#' @param to_pcomp Optional variables to perform PCA on
#' @param center,scale Parameters for `npcomp`
#' @param test Test to use for the MANOVA (defaults to Pillai's trace). See `?summary.manova`
#' @param univariate Whether to perform ANOVA (TRUE) or MANOVA (FALSE)
#' @param add_signif Whether to add significance asterisk labels in an extra column
#' @param parametric Whether to perform parametric tests (linear models instead of Kruskal-Wallis if `univariate` is TRUE, parametric instead of semi-parametric MANOVA if `univariate` is FALSE)
#' @param seed Optional seed for the semi-parametric MANOVA
#' @param iter Number of iterations for the parametric bootstrapping of the semi-parametric MANOVA (defaults to the recommended number 1,000)
#' @param random Optional random effect for fitting a mixed model in univariate ANOVA
#'
#' @details The analysis of variance is performed using a likelihood ratio test between a model including the factor of interest and a null model with intercept only. The LRT is done with models fitted with maximum likelihood. Model comparison between OLS and GLS is done with models fitted with restricted maximum likelihood, that include the factor to be tested (as per Zuur et al. 2009).
#'
#' @return If `manova` is FALSE, data frame containing the results of the ANOVAs for each variable and each subset of the data, including:
#'
#' \itemize{
##'  \item{best}{ The best-fitting model (OLS or GLS)}
##'  \item{df_model}{ Model degrees of freedom}
##'  \item{AICc}{ AICc of the model}
##'  \item{dAICc}{ Difference in AICc between the GLS-model and the OLS-model}
##'  \item{df_LRT}{ Degrees of freedom of the likelihood ratio test}
##'  \item{loglik}{ Log-likelihood of the full model in LRT}
##'  \item{lratio}{ Chi-square value i.e. likelihood ratio between the full and the null model in LRT}
##'  \item{pvalue}{ P-value of the LRT}
##'  \item{posthoc_test}{ Post-hoc test used: Wilcoxon or Tukey}
##'  \item{posthoc_p...}{ Extra columns with the P-values for each contrast in the multiple post-hoc comparisons}
##' }
#'
#' Otherwise, a data frame with MANOVA results for each subset, including, if `semiparametric` is FALSE,
#'
#' \itemize{
#' \item{df}{ The degrees of freedom of the MANOVA}
#' \item{"statistic's name"}{ One of the statistics defined in `summary.manova` (Pillai, Wilks, etc.)}
#' \item{num_df}{ Numerator degrees of freedom of the F-test}
#' \item{denom_df}{ Denominator degrees of freedom of the F-test}
#' \item{pseudoF}{ Approximate F-statistic}
#' \item{pvalue}{ P-value of the F-test}
#' }
#'
#' otherwise, the results of a semi-parametric MANOVA, with:
#'
#' \itemize{
#' \item{term}{ The term being tested, probably the grouping variable}
#' \item{MATS}{ The modified ANOVA-type statistic value}
#' \item{pvalue}{ P-value computed from the parametric bootstrap resampling}
#' }
#'
#' @export
nanova <- function(
data,
variables,
grouping,
nesting = NULL,
univariate = TRUE,
posthoc = TRUE,
to_pcomp = NULL,
center = TRUE,
scale = TRUE,
test = "Pillai",
add_signif = TRUE,
parametric = TRUE,
seed = NULL,
iter = 1000,
random = NULL
) {
library(nlme)
library(MuMIn)
library(MANOVA.RM)
library(tidyverse)
if (is.null(seed)) seed <- sample(1000, 1)
if (!is.null(to_pcomp)) data <- data %>%
cbind(npcomp(
data, to_pcomp, center, scale, nesting, combine = TRUE,
reduce = variables
)$x %>% data.frame %>% dplyr::select(-nesting))
if (is.null(nesting)) {
data$nesting <- factor(1)
nesting <- "nesting"
}
# For each island...
data <- split(data, data[, nesting])
# If Kruskal-Wallis...
if (univariate & !parametric) {
out <- data %>% map_dfr(function(df) {
names(variables) <- variables
map_dfr(
variables,
~ kruskal.test(df[[.x]], df[[grouping]]) %>%
.[c("statistic", "parameter", "p.value")] %>%
data.frame,
.id = "variable"
) %>%
rename(chisq = "statistic", df = "parameter", pvalue = "p.value")
}, .id = nesting)
if (add_signif) out <- out %>% add_signif()
return (out)
}
anovadata <- data.frame(do.call("rbind", lapply(data, function(data) {
data$group <- data[, grouping]
# If MANOVA...
if (!univariate) {
X <- data[, variables] %>% as.matrix
if (parametric) {
fit <- summary(manova(X ~ group, data), test = test)
fit <- fit$stats %>% data.frame %>% .[1, ]
colnames(fit) <- c("df", test, "pseudoF", "num_df", "den_df", "pvalue")
} else {
fit <- MANOVA.wide(
data %>% .[variables] %>% do.call("cbind", .) ~ group,
data = data, seed = seed, iter = iter
)
fit <- fit$MATS %>%
data.frame %>%
rownames_to_column("term") %>%
rename(MATS = "Test.statistic") %>%
mutate(pvalue = fit$resampling %>% data.frame %>% .[["paramBS..MATS."]])
}
return (fit)
}
# Otherwise, for each variable...
t(sapply(variables, function(variable) {
# Note: when using model fitting functions inside another function, avoid
# passing them formulas as objects programatically, that will cause the anova.lme
# call to crash. Instead create extra columns in the data frame with specific names
# and explicitly pass those columns into the model fitting function
data$X <- data[, variable]
# Fit candidate models with different variance structures
mod1 <- gls(X ~ group, data = data)
mod2 <- gls(X ~ group, data = data, weights = varIdent(form = formula(paste("~ 1 |", grouping))))
models <- list(mod1, mod2)
if (!is.null(random)) {
mod3 <- lme(X ~ group, data = data, random = formula(paste("~ 1 |", random)))
mod4 <- lme(
X ~ group, data = data, weights = varIdent(form = formula(paste("~ 1 |", grouping))),
random = formula(paste("~ 1 |", random))
)
models <- c(models, mod3, mod4)
}
print(models[[3]])
# Compare the AICc of the models
aiccs <- unlist(do.call("AICc", models))
dfs <- unname(aiccs[grep("df", names(aiccs))])
aiccs <- unname(aiccs[grep("AICc", names(aiccs))])
best <- which(aiccs == min(aiccs))
best_mod <- models[[best]]
best_df <- dfs[best]
best_aicc <- aiccs[best]
deltas <- aiccs - aiccs[1]
best_delta <- deltas[best]
weights <- exp(-0.5 * deltas)
weights <- weights / sum(weights)
best_weight <- weights[best]
# AIC weights from Burnham, K. P., and D. R. Anderson. 2002. Model selection and multimodel inference : a practical information-theoretic approach. Springer, New York.
# Refit the model with maximum likelihood (instead of REML)
best_mod <- update(best_mod, method = "ML")
# Perform the analysis of variance using likelihood ratio test
best_mod0 <- update(best_mod, X ~ 1) # null model
anova_table <- anova(best_mod, best_mod0) %>% unlist()
# Assemble the output we want to display
dflrt <- anova_table[["df1"]] - anova_table[["df2"]]
loglik <- anova_table[["logLik1"]]
lratio <- anova_table[["L.Ratio2"]]
pvalue <- anova_table[["p-value2"]]
# Prepare output
out <- c(
best_fit = best,
df_model = best_df,
AICc = best_aicc,
dAICc = best_delta,
AICcw = best_weight,
df_LRT = dflrt,
loglik = loglik,
lratio = lratio,
pvalue = pvalue
)
# Multiple comparisons
if (posthoc) {
# If GLS is the best fit...
if (best == 2) {
# Perform multiple comparisons using Wilcoxon tests
posthoc_test <- 2
group_names <- levels(data[, grouping])
# For each comparison of habitats...
posthoc_p <- sapply(seq_len(length(group_names) - 1), function(i) {
sapply(seq(i + 1, length(group_names)), function(j) {
# Perform a Wilcoxon test
pval <- wilcox.test(data[data[grouping] == group_names[j], variable], data[data[grouping] == group_names[i], variable])$p.value
names(pval) <- paste0(group_names[j], "-", group_names[i])
return (pval)
})
}) %>% unlist()
} else {
# Otherwise perform standard posthoc Tukey's HSD test
posthoc_test <- 1
posthoc_p <- TukeyHSD(aov(X ~ group, data))$group
posthoc_p <- posthoc_p[, "p adj"]
}
out <- c(out, posthoc_test = posthoc_test, posthoc_p = posthoc_p)
}
return (out)
}))
})))
if (univariate) {
# Package the output nicely
anovadata <- data.frame(
rep(names(data), each = length(variables)),
variable = rep(variables, length(data)),
anovadata
)
colnames(anovadata)[1] <- nesting
#anovadata <- anovadata %>% mutate(best_fit = factor(best_fit))
if (posthoc) anovadata <- anovadata %>% mutate(posthoc_test = factor(posthoc_test))
levels(anovadata$best) <- c("OLS", "GLS")
if (posthoc) levels(anovadata$posthoc_test) <- c("Tukey", "Wilcoxon")
}
if (add_signif) anovadata <- anovadata %>% add_signif()
return (anovadata)
}
nanova(data, variables, grouping = "habitat", nesting = "island",
univariate = TRUE, parametric = TRUE, random = "site")
#' Nested ANOVA
#'
#' Performs (M)ANOVAs for multiple variables across different subsets of the data. Models fitted with OLS and GLS (allowing one independent residual variance per group) are compared with AIC and the best-fitting model is retained. Multiple post-hoc comparisons can be performed too.
#'
#' @param data A data frame
#' @param variables The variables to analyze
#' @param nesting The name of the nesting factor
#' @param grouping The name of the grouping factor
#' @param posthoc Whether to perform post-hoc tests
#' @param to_pcomp Optional variables to perform PCA on
#' @param center,scale Parameters for `npcomp`
#' @param test Test to use for the MANOVA (defaults to Pillai's trace). See `?summary.manova`
#' @param univariate Whether to perform ANOVA (TRUE) or MANOVA (FALSE)
#' @param add_signif Whether to add significance asterisk labels in an extra column
#' @param parametric Whether to perform parametric tests (linear models instead of Kruskal-Wallis if `univariate` is TRUE, parametric instead of semi-parametric MANOVA if `univariate` is FALSE)
#' @param seed Optional seed for the semi-parametric MANOVA
#' @param iter Number of iterations for the parametric bootstrapping of the semi-parametric MANOVA (defaults to the recommended number 1,000)
#' @param random Optional random effect for fitting a mixed model in univariate ANOVA
#'
#' @details The analysis of variance is performed using a likelihood ratio test between a model including the factor of interest and a null model with intercept only. The LRT is done with models fitted with maximum likelihood. Model comparison between OLS and GLS is done with models fitted with restricted maximum likelihood, that include the factor to be tested (as per Zuur et al. 2009).
#'
#' @return If `manova` is FALSE, data frame containing the results of the ANOVAs for each variable and each subset of the data, including:
#'
#' \itemize{
##'  \item{best}{ The best-fitting model (OLS or GLS)}
##'  \item{df_model}{ Model degrees of freedom}
##'  \item{AICc}{ AICc of the model}
##'  \item{dAICc}{ Difference in AICc between the GLS-model and the OLS-model}
##'  \item{df_LRT}{ Degrees of freedom of the likelihood ratio test}
##'  \item{loglik}{ Log-likelihood of the full model in LRT}
##'  \item{lratio}{ Chi-square value i.e. likelihood ratio between the full and the null model in LRT}
##'  \item{pvalue}{ P-value of the LRT}
##'  \item{posthoc_test}{ Post-hoc test used: Wilcoxon or Tukey}
##'  \item{posthoc_p...}{ Extra columns with the P-values for each contrast in the multiple post-hoc comparisons}
##' }
#'
#' Otherwise, a data frame with MANOVA results for each subset, including, if `semiparametric` is FALSE,
#'
#' \itemize{
#' \item{df}{ The degrees of freedom of the MANOVA}
#' \item{"statistic's name"}{ One of the statistics defined in `summary.manova` (Pillai, Wilks, etc.)}
#' \item{num_df}{ Numerator degrees of freedom of the F-test}
#' \item{denom_df}{ Denominator degrees of freedom of the F-test}
#' \item{pseudoF}{ Approximate F-statistic}
#' \item{pvalue}{ P-value of the F-test}
#' }
#'
#' otherwise, the results of a semi-parametric MANOVA, with:
#'
#' \itemize{
#' \item{term}{ The term being tested, probably the grouping variable}
#' \item{MATS}{ The modified ANOVA-type statistic value}
#' \item{pvalue}{ P-value computed from the parametric bootstrap resampling}
#' }
#'
#' @export
nanova <- function(
data,
variables,
grouping,
nesting = NULL,
univariate = TRUE,
posthoc = TRUE,
to_pcomp = NULL,
center = TRUE,
scale = TRUE,
test = "Pillai",
add_signif = TRUE,
parametric = TRUE,
seed = NULL,
iter = 1000,
random = NULL
) {
library(nlme)
library(MuMIn)
library(MANOVA.RM)
library(tidyverse)
if (is.null(seed)) seed <- sample(1000, 1)
if (!is.null(to_pcomp)) data <- data %>%
cbind(npcomp(
data, to_pcomp, center, scale, nesting, combine = TRUE,
reduce = variables
)$x %>% data.frame %>% dplyr::select(-nesting))
if (is.null(nesting)) {
data$nesting <- factor(1)
nesting <- "nesting"
}
# For each island...
data <- split(data, data[, nesting])
# If Kruskal-Wallis...
if (univariate & !parametric) {
out <- data %>% map_dfr(function(df) {
names(variables) <- variables
map_dfr(
variables,
~ kruskal.test(df[[.x]], df[[grouping]]) %>%
.[c("statistic", "parameter", "p.value")] %>%
data.frame,
.id = "variable"
) %>%
rename(chisq = "statistic", df = "parameter", pvalue = "p.value")
}, .id = nesting)
if (add_signif) out <- out %>% add_signif()
return (out)
}
anovadata <- data.frame(do.call("rbind", lapply(data, function(data) {
data$group <- data[, grouping]
# If MANOVA...
if (!univariate) {
X <- data[, variables] %>% as.matrix
if (parametric) {
fit <- summary(manova(X ~ group, data), test = test)
fit <- fit$stats %>% data.frame %>% .[1, ]
colnames(fit) <- c("df", test, "pseudoF", "num_df", "den_df", "pvalue")
} else {
fit <- MANOVA.wide(
data %>% .[variables] %>% do.call("cbind", .) ~ group,
data = data, seed = seed, iter = iter
)
fit <- fit$MATS %>%
data.frame %>%
rownames_to_column("term") %>%
rename(MATS = "Test.statistic") %>%
mutate(pvalue = fit$resampling %>% data.frame %>% .[["paramBS..MATS."]])
}
return (fit)
}
# Otherwise, for each variable...
t(sapply(variables, function(variable) {
# Note: when using model fitting functions inside another function, avoid
# passing them formulas as objects programatically, that will cause the anova.lme
# call to crash. Instead create extra columns in the data frame with specific names
# and explicitly pass those columns into the model fitting function
data$X <- data[, variable]
# Fit candidate models with different variance structures
mod1 <- gls(X ~ group, data = data)
mod2 <- gls(X ~ group, data = data, weights = varIdent(form = formula(paste("~ 1 |", grouping))))
models <- list(mod1, mod2)
if (!is.null(random)) {
mod3 <- lme(X ~ group, data = data, random = formula(paste("~ 1 |", random)))
mod4 <- lme(
X ~ group, data = data, weights = varIdent(form = formula(paste("~ 1 |", grouping))),
random = formula(paste("~ 1 |", random))
)
models[[3]] <- mod3
models[[4]] <- mod4
}
print(models[[3]])
# Compare the AICc of the models
aiccs <- unlist(do.call("AICc", models))
dfs <- unname(aiccs[grep("df", names(aiccs))])
aiccs <- unname(aiccs[grep("AICc", names(aiccs))])
best <- which(aiccs == min(aiccs))
best_mod <- models[[best]]
best_df <- dfs[best]
best_aicc <- aiccs[best]
deltas <- aiccs - aiccs[1]
best_delta <- deltas[best]
weights <- exp(-0.5 * deltas)
weights <- weights / sum(weights)
best_weight <- weights[best]
# AIC weights from Burnham, K. P., and D. R. Anderson. 2002. Model selection and multimodel inference : a practical information-theoretic approach. Springer, New York.
# Refit the model with maximum likelihood (instead of REML)
best_mod <- update(best_mod, method = "ML")
# Perform the analysis of variance using likelihood ratio test
best_mod0 <- update(best_mod, X ~ 1) # null model
anova_table <- anova(best_mod, best_mod0) %>% unlist()
# Assemble the output we want to display
dflrt <- anova_table[["df1"]] - anova_table[["df2"]]
loglik <- anova_table[["logLik1"]]
lratio <- anova_table[["L.Ratio2"]]
pvalue <- anova_table[["p-value2"]]
# Prepare output
out <- c(
best_fit = best,
df_model = best_df,
AICc = best_aicc,
dAICc = best_delta,
AICcw = best_weight,
df_LRT = dflrt,
loglik = loglik,
lratio = lratio,
pvalue = pvalue
)
# Multiple comparisons
if (posthoc) {
# If GLS is the best fit...
if (best == 2) {
# Perform multiple comparisons using Wilcoxon tests
posthoc_test <- 2
group_names <- levels(data[, grouping])
# For each comparison of habitats...
posthoc_p <- sapply(seq_len(length(group_names) - 1), function(i) {
sapply(seq(i + 1, length(group_names)), function(j) {
# Perform a Wilcoxon test
pval <- wilcox.test(data[data[grouping] == group_names[j], variable], data[data[grouping] == group_names[i], variable])$p.value
names(pval) <- paste0(group_names[j], "-", group_names[i])
return (pval)
})
}) %>% unlist()
} else {
# Otherwise perform standard posthoc Tukey's HSD test
posthoc_test <- 1
posthoc_p <- TukeyHSD(aov(X ~ group, data))$group
posthoc_p <- posthoc_p[, "p adj"]
}
out <- c(out, posthoc_test = posthoc_test, posthoc_p = posthoc_p)
}
return (out)
}))
})))
if (univariate) {
# Package the output nicely
anovadata <- data.frame(
rep(names(data), each = length(variables)),
variable = rep(variables, length(data)),
anovadata
)
colnames(anovadata)[1] <- nesting
#anovadata <- anovadata %>% mutate(best_fit = factor(best_fit))
if (posthoc) anovadata <- anovadata %>% mutate(posthoc_test = factor(posthoc_test))
levels(anovadata$best) <- c("OLS", "GLS")
if (posthoc) levels(anovadata$posthoc_test) <- c("Tukey", "Wilcoxon")
}
if (add_signif) anovadata <- anovadata %>% add_signif()
return (anovadata)
}
nanova(data, variables, grouping = "habitat", nesting = "island",
univariate = TRUE, parametric = TRUE, random = "site")
