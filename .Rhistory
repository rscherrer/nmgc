# Split the data into nesting levels
data <- data %>% split(f = .[, nesting])
verbose <- pb <- TRUE
# Decide on a looping function depending on whether we want a progress bar
if (!verbose) pb <- FALSE
thislapply1 <- thislapply2 <- lapply
if (pb) {
if (nested) {
thislapply1 <- pbapply::pblapply
} else {
thislapply2 <- pbapply::pblapply
}
}
# For each nesting level...
machines <- thislapply1(data, function(data) {
# For each replicate...
thislapply2(seq(nrep), function(i) {
is_fine <- FALSE
# Sample the training and testing sets until valid
while (!is_fine) {
# Randomly assign data to k testing groups
groups <- rep(seq_len(k), each = floor(ptesting * nrow(data)))
if (length(groups) < nrow(data)) {
groups <- c(groups, seq_len(nrow(data) - length(groups)))
}
assertthat::assert_that(length(groups) == nrow(data))
groups <- sample(groups, replace = FALSE)
# Check that each label is sufficiently represented within each training
# group
is_fine <- all(sapply(seq_len(k), function(j) {
represented <- table(data[which(groups != j), grouping])
if (!all(labels %in% names(represented))) return (FALSE)
return (all(represented > minsize))
}))
}
# For each testing group...
lapply(seq_len(k), function(j) {
# Sample indices for a training dataset
training <- which(groups != j)
assertthat::assert_that(length(training) < nrow(data))
# Downsample the training dataset to the size of the least represented
# label
targetsize <- min(table(data[training, grouping]))
training <- do.call(
"c",
lapply(
labels,
function(lab) {
sample(
training[data[training, grouping] == lab], targetsize,
replace = FALSE
)
}
)
)
assertthat::assert_that(
all(table(data[training, grouping]) == targetsize)
)
# Set up model formula
model <- as.formula(
paste(grouping, "~", paste(variables, collapse = " + "))
)
if (method == "SVM") {
# Fit a support vector machine to the data
machine <- rminer::fit(
model, data = data[training, c(variables, grouping)], model = "svm",
kernel = "rbfdot", task = "class"
)
} else if (method == "LDA") {
# Or a linear discriminant analysis
machine <- MASS::lda(
formula = model, data = data[training, c(variables, grouping)]
)
} else stop("unknown method")
# Sensitivity analysis of the fitted model
imp <- NULL
if (importance) {
if (method == "LDA") {
imp <- rminer::Importance(
machine, data = data[training, c(variables, grouping)],
PRED = function(M, data) predict(M, data)$class
)
} else  if (method == "SVM") {
imp <- rminer::Importance(
machine, data = data[training, c(variables, grouping)]
)
}
imp <- imp$imp[seq_along(variables)]
names(imp) <- variables
}
# Predict the labels of the remaining data
predictions <- rminer::predict(
machine, newdata = data[groups == j, variables]
)
if (method == "LDA") predictions <- predictions$class
# Compare true and predicted labels
conf <- table(predictions, data[[grouping]][groups == j])
if (!return_machine) machine <- NULL
# Return the confusion matrix, the results of the importance analysis
# and the machine itself, if needed
return (list(confmat = conf, importance = imp, machine = machine))
}) # end of cross-validation bin
}) # end of replicate
}) # end of nesting level
method <- "LDA"
# For each nesting level...
machines <- thislapply1(data, function(data) {
# For each replicate...
thislapply2(seq(nrep), function(i) {
is_fine <- FALSE
# Sample the training and testing sets until valid
while (!is_fine) {
# Randomly assign data to k testing groups
groups <- rep(seq_len(k), each = floor(ptesting * nrow(data)))
if (length(groups) < nrow(data)) {
groups <- c(groups, seq_len(nrow(data) - length(groups)))
}
assertthat::assert_that(length(groups) == nrow(data))
groups <- sample(groups, replace = FALSE)
# Check that each label is sufficiently represented within each training
# group
is_fine <- all(sapply(seq_len(k), function(j) {
represented <- table(data[which(groups != j), grouping])
if (!all(labels %in% names(represented))) return (FALSE)
return (all(represented > minsize))
}))
}
# For each testing group...
lapply(seq_len(k), function(j) {
# Sample indices for a training dataset
training <- which(groups != j)
assertthat::assert_that(length(training) < nrow(data))
# Downsample the training dataset to the size of the least represented
# label
targetsize <- min(table(data[training, grouping]))
training <- do.call(
"c",
lapply(
labels,
function(lab) {
sample(
training[data[training, grouping] == lab], targetsize,
replace = FALSE
)
}
)
)
assertthat::assert_that(
all(table(data[training, grouping]) == targetsize)
)
# Set up model formula
model <- as.formula(
paste(grouping, "~", paste(variables, collapse = " + "))
)
if (method == "SVM") {
# Fit a support vector machine to the data
machine <- rminer::fit(
model, data = data[training, c(variables, grouping)], model = "svm",
kernel = "rbfdot", task = "class"
)
} else if (method == "LDA") {
# Or a linear discriminant analysis
machine <- MASS::lda(
formula = model, data = data[training, c(variables, grouping)]
)
} else stop("unknown method")
# Sensitivity analysis of the fitted model
imp <- NULL
if (importance) {
if (method == "LDA") {
imp <- rminer::Importance(
machine, data = data[training, c(variables, grouping)],
PRED = function(M, data) predict(M, data)$class
)
} else  if (method == "SVM") {
imp <- rminer::Importance(
machine, data = data[training, c(variables, grouping)]
)
}
imp <- imp$imp[seq_along(variables)]
names(imp) <- variables
}
# Predict the labels of the remaining data
predictions <- rminer::predict(
machine, newdata = data[groups == j, variables]
)
if (method == "LDA") predictions <- predictions$class
# Compare true and predicted labels
conf <- table(predictions, data[[grouping]][groups == j])
if (!return_machine) machine <- NULL
# Return the confusion matrix, the results of the importance analysis
# and the machine itself, if needed
return (list(confmat = conf, importance = imp, machine = machine))
}) # end of cross-validation bin
}) # end of replicate
}) # end of nesting level
importance <- FALSE
# For each nesting level...
machines <- thislapply1(data, function(data) {
# For each replicate...
thislapply2(seq(nrep), function(i) {
is_fine <- FALSE
# Sample the training and testing sets until valid
while (!is_fine) {
# Randomly assign data to k testing groups
groups <- rep(seq_len(k), each = floor(ptesting * nrow(data)))
if (length(groups) < nrow(data)) {
groups <- c(groups, seq_len(nrow(data) - length(groups)))
}
assertthat::assert_that(length(groups) == nrow(data))
groups <- sample(groups, replace = FALSE)
# Check that each label is sufficiently represented within each training
# group
is_fine <- all(sapply(seq_len(k), function(j) {
represented <- table(data[which(groups != j), grouping])
if (!all(labels %in% names(represented))) return (FALSE)
return (all(represented > minsize))
}))
}
# For each testing group...
lapply(seq_len(k), function(j) {
# Sample indices for a training dataset
training <- which(groups != j)
assertthat::assert_that(length(training) < nrow(data))
# Downsample the training dataset to the size of the least represented
# label
targetsize <- min(table(data[training, grouping]))
training <- do.call(
"c",
lapply(
labels,
function(lab) {
sample(
training[data[training, grouping] == lab], targetsize,
replace = FALSE
)
}
)
)
assertthat::assert_that(
all(table(data[training, grouping]) == targetsize)
)
# Set up model formula
model <- as.formula(
paste(grouping, "~", paste(variables, collapse = " + "))
)
if (method == "SVM") {
# Fit a support vector machine to the data
machine <- rminer::fit(
model, data = data[training, c(variables, grouping)], model = "svm",
kernel = "rbfdot", task = "class"
)
} else if (method == "LDA") {
# Or a linear discriminant analysis
machine <- MASS::lda(
formula = model, data = data[training, c(variables, grouping)]
)
} else stop("unknown method")
# Sensitivity analysis of the fitted model
imp <- NULL
if (importance) {
if (method == "LDA") {
imp <- rminer::Importance(
machine, data = data[training, c(variables, grouping)],
PRED = function(M, data) predict(M, data)$class
)
} else  if (method == "SVM") {
imp <- rminer::Importance(
machine, data = data[training, c(variables, grouping)]
)
}
imp <- imp$imp[seq_along(variables)]
names(imp) <- variables
}
# Predict the labels of the remaining data
predictions <- rminer::predict(
machine, newdata = data[groups == j, variables]
)
if (method == "LDA") predictions <- predictions$class
# Compare true and predicted labels
conf <- table(predictions, data[[grouping]][groups == j])
if (!return_machine) machine <- NULL
# Return the confusion matrix, the results of the importance analysis
# and the machine itself, if needed
return (list(confmat = conf, importance = imp, machine = machine))
}) # end of cross-validation bin
}) # end of replicate
}) # end of nesting level
return_machine <- FALSE
# For each nesting level...
machines <- thislapply1(data, function(data) {
# For each replicate...
thislapply2(seq(nrep), function(i) {
is_fine <- FALSE
# Sample the training and testing sets until valid
while (!is_fine) {
# Randomly assign data to k testing groups
groups <- rep(seq_len(k), each = floor(ptesting * nrow(data)))
if (length(groups) < nrow(data)) {
groups <- c(groups, seq_len(nrow(data) - length(groups)))
}
assertthat::assert_that(length(groups) == nrow(data))
groups <- sample(groups, replace = FALSE)
# Check that each label is sufficiently represented within each training
# group
is_fine <- all(sapply(seq_len(k), function(j) {
represented <- table(data[which(groups != j), grouping])
if (!all(labels %in% names(represented))) return (FALSE)
return (all(represented > minsize))
}))
}
# For each testing group...
lapply(seq_len(k), function(j) {
# Sample indices for a training dataset
training <- which(groups != j)
assertthat::assert_that(length(training) < nrow(data))
# Downsample the training dataset to the size of the least represented
# label
targetsize <- min(table(data[training, grouping]))
training <- do.call(
"c",
lapply(
labels,
function(lab) {
sample(
training[data[training, grouping] == lab], targetsize,
replace = FALSE
)
}
)
)
assertthat::assert_that(
all(table(data[training, grouping]) == targetsize)
)
# Set up model formula
model <- as.formula(
paste(grouping, "~", paste(variables, collapse = " + "))
)
if (method == "SVM") {
# Fit a support vector machine to the data
machine <- rminer::fit(
model, data = data[training, c(variables, grouping)], model = "svm",
kernel = "rbfdot", task = "class"
)
} else if (method == "LDA") {
# Or a linear discriminant analysis
machine <- MASS::lda(
formula = model, data = data[training, c(variables, grouping)]
)
} else stop("unknown method")
# Sensitivity analysis of the fitted model
imp <- NULL
if (importance) {
if (method == "LDA") {
imp <- rminer::Importance(
machine, data = data[training, c(variables, grouping)],
PRED = function(M, data) predict(M, data)$class
)
} else  if (method == "SVM") {
imp <- rminer::Importance(
machine, data = data[training, c(variables, grouping)]
)
}
imp <- imp$imp[seq_along(variables)]
names(imp) <- variables
}
# Predict the labels of the remaining data
predictions <- rminer::predict(
machine, newdata = data[groups == j, variables]
)
if (method == "LDA") predictions <- predictions$class
# Compare true and predicted labels
conf <- table(predictions, data[[grouping]][groups == j])
if (!return_machine) machine <- NULL
# Return the confusion matrix, the results of the importance analysis
# and the machine itself, if needed
return (list(confmat = conf, importance = imp, machine = machine))
}) # end of cross-validation bin
}) # end of replicate
}) # end of nesting level
res
machines
# Prepare a data frame with results for each machine
res <- tidyr::expand_grid(lvl = names(data), repl = seq(nrep), kbin = seq(k))
# Fill in that data frame with the output of each machine
res <- res %>%
dplyr::group_by(lvl, repl, kbin) %>%
tidyr::nest() %>%
dplyr::mutate(
# Confusion matrix
confmat = purrr::pmap(
list(lvl, repl, kbin),
~ purrr::pluck(machines, ..1, ..2, ..3)$confmat
),
# Vector of importance scores
importance = purrr::pmap(
list(lvl, repl, kbin),
~ purrr::pluck(machines, ..1, ..2, ..3)$importance
),
# Fitted machine
machine = purrr::pmap(
list(lvl, repl, kbin),
~ purrr::pluck(machines, ..1, ..2, ..3)$machine
)
) %>%
dplyr::select(-data) %>%
dplyr::ungroup() %>%
dplyr::mutate(
accuracy = purrr::map_dbl(confmat, pdiag),
ntested = purrr::map_int(confmat, sum)
)
library(nmgc)
# Fill in that data frame with the output of each machine
res <- res %>%
dplyr::group_by(lvl, repl, kbin) %>%
tidyr::nest() %>%
dplyr::mutate(
# Confusion matrix
confmat = purrr::pmap(
list(lvl, repl, kbin),
~ purrr::pluck(machines, ..1, ..2, ..3)$confmat
),
# Vector of importance scores
importance = purrr::pmap(
list(lvl, repl, kbin),
~ purrr::pluck(machines, ..1, ..2, ..3)$importance
),
# Fitted machine
machine = purrr::pmap(
list(lvl, repl, kbin),
~ purrr::pluck(machines, ..1, ..2, ..3)$machine
)
) %>%
dplyr::select(-data) %>%
dplyr::ungroup() %>%
dplyr::mutate(
accuracy = purrr::map_dbl(confmat, pdiag),
ntested = purrr::map_int(confmat, sum)
)
# Summarize accuracy across machines for each replicate
res2 <- res %>%
dplyr::group_by(lvl, repl) %>%
purrr::nest() %>%
dplyr::mutate(
# Summed confusion matrix
confmat = purrr::map(data, ~ Reduce('+', .x$confmat)),
# Total accuracy
accuracy = purrr::map_dbl(confmat, pdiag),
# Number of tested points (= sample size of each nesting level)
ntested = purrr::map_int(confmat, sum),
# Is accuracy greater than expected by chance? (one-tailed binomial)
pvalue = purrr::map2_dbl(
confmat, ntested,
~ binom.test(
x = sum(diag(.x)),
p = 1 / length(labels),
n = .y,
alternative = "greater"
)$p.value
)
) %>%
dplyr::ungroup() %>%
dplyr::select(-data)
# Summarize accuracy across machines for each replicate
res2 <- res %>%
dplyr::group_by(lvl, repl) %>%
tidyr::nest() %>%
dplyr::mutate(
# Summed confusion matrix
confmat = purrr::map(data, ~ Reduce('+', .x$confmat)),
# Total accuracy
accuracy = purrr::map_dbl(confmat, pdiag),
# Number of tested points (= sample size of each nesting level)
ntested = purrr::map_int(confmat, sum),
# Is accuracy greater than expected by chance? (one-tailed binomial)
pvalue = purrr::map2_dbl(
confmat, ntested,
~ binom.test(
x = sum(diag(.x)),
p = 1 / length(labels),
n = .y,
alternative = "greater"
)$p.value
)
) %>%
dplyr::ungroup() %>%
dplyr::select(-data)
# Summarize the results over replicates for each nesting level
# P-values are combined using the Z-transform test
res2 <- res2 %>%
dplyr::mutate(
# Convert one-tailed P-values into Z-scores
zvalue = qnorm(p = pvalue, mean = 0, sd = 1)
) %>%
dplyr::group_by(lvl) %>%
tidyr::nest() %>%
dplyr::mutate(
# Average confusion matrix
confmat = purrr::map(data, ~ mavg(.x$confmat)),
# Average accuracy
mean = purrr::map_dbl(data, ~ mean(.x$accuracy)),
# Standard error of accuracy
stderr = purrr::map_dbl(data, ~ sqrt(var(.x$accuracy) / dplyr::n())),
# Stouffer's Z-statistic
zs = purrr::map_dbl(data, ~ sum(.x$zvalue) / sqrt(dplyr::n())),
# Combined P-value over replicates
pcombined = purrr::map_dbl(zs, pnorm, mean = 0, sd = 1)
) %>%
dplyr::select(-data) %>%
dplyr::ungroup()
res2
res
