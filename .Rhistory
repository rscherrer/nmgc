} else if (method == "LDA") {
# Or a linear discriminant analysis
machine <- MASS::lda(
formula = model, data = data[training, c(variables, grouping)]
)
} else stop("unknown method")
# Sensitivity analysis of the fitted model
imp <- NULL
if (importance) {
if (method == "LDA") {
imp <- rminer::Importance(
machine, data = data[training, c(variables, grouping)],
PRED = function(M, data) predict(M, data)$class
)
} else  if (method == "SVM") {
imp <- rminer::Importance(
machine, data = data[training, c(variables, grouping)]
)
}
imp <- imp$imp[seq_along(variables)]
names(imp) <- variables
}
# Predict the labels of the remaining data
predictions <- rminer::predict(
machine, newdata = data[groups == j, variables]
)
if (method == "LDA") predictions <- predictions$class
# Compare true and predicted labels
conf <- table(predictions, data[[grouping]][groups == j])
if (!return_machine) machine <- NULL
# Return the confusion matrix, the results of the importance analysis
# and the machine itself, if needed
return (list(confmat = conf, importance = imp, machine = machine))
}) # end of cross-validation bin
}) # end of replicate
}) # end of nesting level
method <- "LDA"
# For each nesting level...
machines <- thislapply1(data, function(data) {
# For each replicate...
thislapply2(seq(nrep), function(i) {
is_fine <- FALSE
# Sample the training and testing sets until valid
while (!is_fine) {
# Randomly assign data to k testing groups
groups <- rep(seq_len(k), each = floor(ptesting * nrow(data)))
if (length(groups) < nrow(data)) {
groups <- c(groups, seq_len(nrow(data) - length(groups)))
}
assertthat::assert_that(length(groups) == nrow(data))
groups <- sample(groups, replace = FALSE)
# Check that each label is sufficiently represented within each training
# group
is_fine <- all(sapply(seq_len(k), function(j) {
represented <- table(data[which(groups != j), grouping])
if (!all(labels %in% names(represented))) return (FALSE)
return (all(represented > minsize))
}))
}
# For each testing group...
lapply(seq_len(k), function(j) {
# Sample indices for a training dataset
training <- which(groups != j)
assertthat::assert_that(length(training) < nrow(data))
# Downsample the training dataset to the size of the least represented
# label
targetsize <- min(table(data[training, grouping]))
training <- do.call(
"c",
lapply(
labels,
function(lab) {
sample(
training[data[training, grouping] == lab], targetsize,
replace = FALSE
)
}
)
)
assertthat::assert_that(
all(table(data[training, grouping]) == targetsize)
)
# Set up model formula
model <- as.formula(
paste(grouping, "~", paste(variables, collapse = " + "))
)
if (method == "SVM") {
# Fit a support vector machine to the data
machine <- rminer::fit(
model, data = data[training, c(variables, grouping)], model = "svm",
kernel = "rbfdot", task = "class"
)
} else if (method == "LDA") {
# Or a linear discriminant analysis
machine <- MASS::lda(
formula = model, data = data[training, c(variables, grouping)]
)
} else stop("unknown method")
# Sensitivity analysis of the fitted model
imp <- NULL
if (importance) {
if (method == "LDA") {
imp <- rminer::Importance(
machine, data = data[training, c(variables, grouping)],
PRED = function(M, data) predict(M, data)$class
)
} else  if (method == "SVM") {
imp <- rminer::Importance(
machine, data = data[training, c(variables, grouping)]
)
}
imp <- imp$imp[seq_along(variables)]
names(imp) <- variables
}
# Predict the labels of the remaining data
predictions <- rminer::predict(
machine, newdata = data[groups == j, variables]
)
if (method == "LDA") predictions <- predictions$class
# Compare true and predicted labels
conf <- table(predictions, data[[grouping]][groups == j])
if (!return_machine) machine <- NULL
# Return the confusion matrix, the results of the importance analysis
# and the machine itself, if needed
return (list(confmat = conf, importance = imp, machine = machine))
}) # end of cross-validation bin
}) # end of replicate
}) # end of nesting level
importance <- FALSE
# For each nesting level...
machines <- thislapply1(data, function(data) {
# For each replicate...
thislapply2(seq(nrep), function(i) {
is_fine <- FALSE
# Sample the training and testing sets until valid
while (!is_fine) {
# Randomly assign data to k testing groups
groups <- rep(seq_len(k), each = floor(ptesting * nrow(data)))
if (length(groups) < nrow(data)) {
groups <- c(groups, seq_len(nrow(data) - length(groups)))
}
assertthat::assert_that(length(groups) == nrow(data))
groups <- sample(groups, replace = FALSE)
# Check that each label is sufficiently represented within each training
# group
is_fine <- all(sapply(seq_len(k), function(j) {
represented <- table(data[which(groups != j), grouping])
if (!all(labels %in% names(represented))) return (FALSE)
return (all(represented > minsize))
}))
}
# For each testing group...
lapply(seq_len(k), function(j) {
# Sample indices for a training dataset
training <- which(groups != j)
assertthat::assert_that(length(training) < nrow(data))
# Downsample the training dataset to the size of the least represented
# label
targetsize <- min(table(data[training, grouping]))
training <- do.call(
"c",
lapply(
labels,
function(lab) {
sample(
training[data[training, grouping] == lab], targetsize,
replace = FALSE
)
}
)
)
assertthat::assert_that(
all(table(data[training, grouping]) == targetsize)
)
# Set up model formula
model <- as.formula(
paste(grouping, "~", paste(variables, collapse = " + "))
)
if (method == "SVM") {
# Fit a support vector machine to the data
machine <- rminer::fit(
model, data = data[training, c(variables, grouping)], model = "svm",
kernel = "rbfdot", task = "class"
)
} else if (method == "LDA") {
# Or a linear discriminant analysis
machine <- MASS::lda(
formula = model, data = data[training, c(variables, grouping)]
)
} else stop("unknown method")
# Sensitivity analysis of the fitted model
imp <- NULL
if (importance) {
if (method == "LDA") {
imp <- rminer::Importance(
machine, data = data[training, c(variables, grouping)],
PRED = function(M, data) predict(M, data)$class
)
} else  if (method == "SVM") {
imp <- rminer::Importance(
machine, data = data[training, c(variables, grouping)]
)
}
imp <- imp$imp[seq_along(variables)]
names(imp) <- variables
}
# Predict the labels of the remaining data
predictions <- rminer::predict(
machine, newdata = data[groups == j, variables]
)
if (method == "LDA") predictions <- predictions$class
# Compare true and predicted labels
conf <- table(predictions, data[[grouping]][groups == j])
if (!return_machine) machine <- NULL
# Return the confusion matrix, the results of the importance analysis
# and the machine itself, if needed
return (list(confmat = conf, importance = imp, machine = machine))
}) # end of cross-validation bin
}) # end of replicate
}) # end of nesting level
return_machine <- FALSE
# For each nesting level...
machines <- thislapply1(data, function(data) {
# For each replicate...
thislapply2(seq(nrep), function(i) {
is_fine <- FALSE
# Sample the training and testing sets until valid
while (!is_fine) {
# Randomly assign data to k testing groups
groups <- rep(seq_len(k), each = floor(ptesting * nrow(data)))
if (length(groups) < nrow(data)) {
groups <- c(groups, seq_len(nrow(data) - length(groups)))
}
assertthat::assert_that(length(groups) == nrow(data))
groups <- sample(groups, replace = FALSE)
# Check that each label is sufficiently represented within each training
# group
is_fine <- all(sapply(seq_len(k), function(j) {
represented <- table(data[which(groups != j), grouping])
if (!all(labels %in% names(represented))) return (FALSE)
return (all(represented > minsize))
}))
}
# For each testing group...
lapply(seq_len(k), function(j) {
# Sample indices for a training dataset
training <- which(groups != j)
assertthat::assert_that(length(training) < nrow(data))
# Downsample the training dataset to the size of the least represented
# label
targetsize <- min(table(data[training, grouping]))
training <- do.call(
"c",
lapply(
labels,
function(lab) {
sample(
training[data[training, grouping] == lab], targetsize,
replace = FALSE
)
}
)
)
assertthat::assert_that(
all(table(data[training, grouping]) == targetsize)
)
# Set up model formula
model <- as.formula(
paste(grouping, "~", paste(variables, collapse = " + "))
)
if (method == "SVM") {
# Fit a support vector machine to the data
machine <- rminer::fit(
model, data = data[training, c(variables, grouping)], model = "svm",
kernel = "rbfdot", task = "class"
)
} else if (method == "LDA") {
# Or a linear discriminant analysis
machine <- MASS::lda(
formula = model, data = data[training, c(variables, grouping)]
)
} else stop("unknown method")
# Sensitivity analysis of the fitted model
imp <- NULL
if (importance) {
if (method == "LDA") {
imp <- rminer::Importance(
machine, data = data[training, c(variables, grouping)],
PRED = function(M, data) predict(M, data)$class
)
} else  if (method == "SVM") {
imp <- rminer::Importance(
machine, data = data[training, c(variables, grouping)]
)
}
imp <- imp$imp[seq_along(variables)]
names(imp) <- variables
}
# Predict the labels of the remaining data
predictions <- rminer::predict(
machine, newdata = data[groups == j, variables]
)
if (method == "LDA") predictions <- predictions$class
# Compare true and predicted labels
conf <- table(predictions, data[[grouping]][groups == j])
if (!return_machine) machine <- NULL
# Return the confusion matrix, the results of the importance analysis
# and the machine itself, if needed
return (list(confmat = conf, importance = imp, machine = machine))
}) # end of cross-validation bin
}) # end of replicate
}) # end of nesting level
# Prepare a data frame with results for each machine
res <- expand_grid(lvl = names(data), repl = seq(nrep), kbin = seq(k))
# Fill in that data frame with the output of each machine
res <- res %>%
group_by(lvl, repl, kbin) %>%
nest() %>%
mutate(
# Confusion matrix
confmat = pmap(
list(lvl, repl, kbin), ~ pluck(machines, ..1, ..2, ..3)$confmat
),
# Vector of importance scores
importance = pmap(
list(lvl, repl, kbin), ~ pluck(machines, ..1, ..2, ..3)$importance
),
# Fitted machine
machine = pmap(
list(lvl, repl, kbin), ~ pluck(machines, ..1, ..2, ..3)$machine
)
) %>%
select(-data) %>%
ungroup() %>%
mutate(
accuracy = map_dbl(confmat, pdiag),
ntested = map_int(confmat, sum)
)
res
# Summarize accuracy across machines for each replicate
res <- res %>%
group_by(lvl, repl) %>%
nest() %>%
mutate(
# Summed confusion matrix
confmat = map(data, ~ Reduce('+', .x$confmat)),
# Total accuracy
accuracy = map_dbl(confmat, pdiag),
# Number of tested points (= sample size of each nesting level)
ntested = map_int(confmat, sum),
# Is accuracy greater than expected by chance?
pvalue = map2_dbl(
confmat, ntested,
~ binom.test(
x = sum(diag(.x)),
p = 1 / length(labels),
n = .y,
alternative = "greater"
)$p.value
)
) %>%
ungroup() %>%
select(-data)
res
res %>%
group_by(lvl) %>%
nest() %>%
mutate(
confmat = map(data, ~ .x$confmat)
)
res %>%
group_by(lvl) %>%
nest() %>%
mutate(
confmat = map(data, ~ mavg(.x$confmat))
)
res %>%
group_by(lvl) %>%
nest()
res
res %>%
group_by(lvl) %>%
nest() %>%
mutate(
confmat = map(data, ~ mavg(.x$confmat)),
mean = mean(accuracy)
)
res %>%
group_by(lvl) %>%
nest() %>%
mutate(
confmat = map(data, ~ mavg(.x$confmat)),
mean = map(data, ~ mean(.x$accuracy))
)
res %>%
group_by(lvl) %>%
nest() %>%
mutate(
confmat = map(data, ~ mavg(.x$confmat)),
mean = map_dbl(data, ~ mean(.x$accuracy))
)
res %>%
group_by(lvl) %>%
nest() %>%
mutate(
confmat = map(data, ~ mavg(.x$confmat)),
mean = map_dbl(data, ~ mean(.x$accuracy)),
stderr = map_dbl(data, ~ sqrt(var(.x$accuracy) / n()))
)
?rnorm
pnorm(0.05, mean = 0, sd = 1)
qnorm(0.05, mean = 0, sd = 1)
qnorm(0.95, mean = 0, sd = 1)
res %>%
group_by(lvl) %>%
nest() %>%
mutate(
confmat = map(data, ~ mavg(.x$confmat)),
mean = map_dbl(data, ~ mean(.x$accuracy)),
stderr = map_dbl(data, ~ sqrt(var(.x$accuracy) / n()))
)
res
group_by(lvl) %>%
nest() %>%
mutate(
confmat = map(data, ~ mavg(.x$confmat)),
mean = map_dbl(data, ~ mean(.x$accuracy)),
stderr = map_dbl(data, ~ sqrt(var(.x$accuracy) / n()))
)
res
res
res %>%
mutate(
zvalue = qnorm(p = pvalue, mean = 0, sd = 1)
) %>%
group_by(lvl) %>%
nest() %>%
mutate(
confmat = map(data, ~ mavg(.x$confmat)),
mean = map_dbl(data, ~ mean(.x$accuracy)),
stderr = map_dbl(data, ~ sqrt(var(.x$accuracy) / n()))
)
res %>%
mutate(
zvalue = qnorm(p = pvalue, mean = 0, sd = 1)
)
res %>%
mutate(
zvalue = qnorm(p = pvalue, mean = 0, sd = 1)
) %>%
group_by(lvl) %>%
nest() %>%
mutate(
confmat = map(data, ~ mavg(.x$confmat)),
mean = map_dbl(data, ~ mean(.x$accuracy)),
stderr = map_dbl(data, ~ sqrt(var(.x$accuracy) / n())),
zs = map(data, ~ sum(.x$zvalue) / sqrt(n()))
)
res %>%
mutate(
zvalue = qnorm(p = pvalue, mean = 0, sd = 1)
) %>%
group_by(lvl) %>%
nest() %>%
mutate(
confmat = map(data, ~ mavg(.x$confmat)),
mean = map_dbl(data, ~ mean(.x$accuracy)),
stderr = map_dbl(data, ~ sqrt(var(.x$accuracy) / n())),
zs = map_dbl(data, ~ sum(.x$zvalue) / sqrt(n()))
)
pnorm(1.6, mean = 0, sd = 1)
pnorm(-1.6, mean = 0, sd = 1)
res %>%
mutate(
zvalue = qnorm(p = pvalue, mean = 0, sd = 1)
) %>%
group_by(lvl) %>%
nest() %>%
mutate(
confmat = map(data, ~ mavg(.x$confmat)),
mean = map_dbl(data, ~ mean(.x$accuracy)),
stderr = map_dbl(data, ~ sqrt(var(.x$accuracy) / n())),
zs = map_dbl(data, ~ sum(.x$zvalue) / sqrt(n())),
pcombined = map(zs, pnorm, mean = 0, sd = 1)
)
res %>%
mutate(
zvalue = qnorm(p = pvalue, mean = 0, sd = 1)
) %>%
group_by(lvl) %>%
nest() %>%
mutate(
confmat = map(data, ~ mavg(.x$confmat)),
mean = map_dbl(data, ~ mean(.x$accuracy)),
stderr = map_dbl(data, ~ sqrt(var(.x$accuracy) / n())),
zs = map_dbl(data, ~ sum(.x$zvalue) / sqrt(n())),
pcombined = map_dbl(zs, pnorm, mean = 0, sd = 1)
)
res %>%
mutate(
zvalue = qnorm(p = pvalue, mean = 0, sd = 1)
) %>%
group_by(lvl) %>%
nest() %>%
mutate(
confmat = map(data, ~ mavg(.x$confmat)),
mean = map_dbl(data, ~ mean(.x$accuracy)),
stderr = map_dbl(data, ~ sqrt(var(.x$accuracy) / n())),
zs = map_dbl(data, ~ sum(.x$zvalue) / sqrt(n())),
pcombined = map_dbl(zs, pnorm, mean = 0, sd = 1)
) %>%
select(-data)
