% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/classify.R
\name{classify}
\alias{classify}
\title{Classification analysis}
\usage{
classify(
  data,
  variables,
  grouping,
  nesting = NULL,
  method = "SVM",
  k = 5,
  nrep = 1,
  nperm = 0,
  minsize = 5,
  seed = NULL,
  importance = FALSE,
  getmachine = FALSE,
  verbose = TRUE,
  pb = TRUE,
  digest = TRUE,
  topcomp = NULL,
  pccenter = TRUE,
  pcscale = TRUE,
  showconf = TRUE,
  showbinom = TRUE,
  showpval = TRUE,
  cnorm = 2,
  clims = c(0, 1),
  clow = "white",
  chigh = "darkgreen",
  hbins = 30,
  hfill = "seagreen",
  halpha = 0.5,
  cxlim = c(0.75, 1),
  cylim = c(0.3, 0.85),
  blty = 1,
  prounding = 4,
  ptoshow = "prandom",
  psignif = 0.05,
  px = 1,
  py = 0.9,
  phjust = 1,
  psize = 3
)
}
\arguments{
\item{data}{A data frame}

\item{variables}{The variables used to classify}

\item{grouping}{Name of the grouping variable (the labels)}

\item{nesting}{Optional nesting variable, if the analysis must be conducted separately on different subsets of the data}

\item{method}{The data mining model used. Currently supports "SVM" and "LDA".}

\item{k}{Number of bins for the k-fold cross-validation procedure}

\item{nrep}{Number of replicate analyses (i.e. number of k-fold cross validations)}

\item{nperm}{Number of permutations in the randomization test. Use 0 to not conduct a randomization test.}

\item{minsize}{Minimum size required per group for a training data set}

\item{seed}{Optional random seed to reset at the beginning}

\item{importance}{Whether to perform sensitivity analysis on the input (takes a while)}

\item{getmachine}{Whether to return the machines (takes space)}

\item{verbose}{Whether to display messages}

\item{pb}{Whether to display progress bars}

\item{digest}{Whether to return the results in a summarized format. If FALSE, returns the raw results for each machine.}

\item{topcomp}{Variable to perform PCA on}

\item{pccenter}{Center the PCA}

\item{pcscale}{Scale the PCA}

\item{showconf}{Whether to show confusion matrices as insets on accuracy histograms}

\item{showbinom}{Whether to show a binomial null distribution on accuracy histograms}

\item{showpval}{Whether to show P-values on accuracy histograms}

\item{cnorm}{Integer indicating whether to normalize the confusion matrices on display so as to make rows sum to one (1), or columns (2), or neither (0).}

\item{clims}{Limits of the range of frequencies displayed in the confusion matrices}

\item{clow}{Color associated with the lowest frequency in confusion matrix heatmaps}

\item{chigh}{Color associated with the highest frequency in confusion matrix heatmaps}

\item{hbins}{Number of bins in the histogram of accuracy scores}

\item{hfill}{Color of the histogram of accuracy scores}

\item{halpha}{Transparency of the histogram of accuracy scores}

\item{cxlim}{Vector of two values containing the bounds of the inset confusion matrices along the horizontal axis}

\item{cylim}{Vector of two values containing the bounds of the inset confusion matrices along the vertical axis (in proportion of the height of the plot)}

\item{blty}{Line type for displaying the null binomial distribution}

\item{prounding}{Number of decimal places to round P-values on display}

\item{ptoshow}{What P-value to show on the histogram plots (either of "pbinom" for the binomial test or "prandom" for the randomization test)}

\item{psignif}{Significance level for P-values on display. An asterisk will be added to each significant P-value. Use zero to avoid displaying any asterisk.}

\item{px}{Horizontal location of the P-values}

\item{py}{Vertical location of the P-values (in proportion of the height of the plot)}

\item{phjust}{Horizontal justification of the P-values (e.g. 1 to align them to the right, 0 to the left and 0.5 to center them)}

\item{psize}{Font size of the P-values on display}
}
\value{
If \code{digest} is FALSE, this function returns a nested list of raw classification results on three levels. The first level is for each separate plot, or nesting level, in the nested analysis. The second level is for each replicate analysis within each plot. The third level is for each machine, i.e. each cross-validation bin within each replicate. This third level is itself a list with for each machine, the confusion matrix from the classification (\code{conf}), a vector of importance scores for each variable from the sensitivity analysis (\code{imp}, only if \code{importance} is TRUE) and the trained machine itself (\code{machine}, only if \code{getmachine} is TRUE). These are the raw results for each machine. If \code{digest} is TRUE, however, the function returns a summarized version of the results. The output is then a list with three fields. The first field is a summary table (\code{summary}) of the results with, for each nesting level, the mean accuracy score (\code{accu}), the sample size (\code{n}, the total number of points tested within each replicate), the proportion of the data used for testing (\code{ptest}, which depends on \code{k}), the number of points tested by each machine (\code{ntest}), the P-value from a binomial test assessing the significance of the average accuracy score (\code{pbinom}) and the P-value from an equivalent randomization test (\code{prandom}), where the null distribution is computed by training \code{nperm} replicates on permuted data. There are three additional list-columns with, for each nesting level, the average confusion matrix over all replicates (\code{conf}), a data frame of importance scores (\code{imp}) for each variable (in columns) for each machine (in rows), and a vector of acccuracy scores (\code{accus}) where the \code{nrep} first values are for the replicates and the remaining \code{nperm} were measured on randomized data. Note that accuracy scores are measured by summing the confusion matrices of all cross-validation bins into one, yielding one score per replicate.
}
\description{
Perform a replicated classification analysis of a multivariate dataset into categorical labels using machine learning tools and k-fold cross validation
}
