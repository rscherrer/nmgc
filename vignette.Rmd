---
title: "nmgc: Nested Multivariate Group Comparisons in R"
author: "Rapha&euml;l Scherrer"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document:
    keep_md: yes
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
---

This package provides tools to conduct group comparisons on multivariate datasets that typically have a nested design, that is, datasets where group comparisons must be repeated on multiple subsets of the data. This is typically the case, for example, for replicate samples on multiple islands across an archipelago. This package wraps around tools available in R to facilitate the analysis of such datasets. Most functions in the package take a data frame as argument, a set of `variables` to analyze, a `grouping` variable to perform the group comparison, and an optional `nesting` variable that indicates the different subsets to analyze separately. The package includes group comparison tests such as MANOVA, ANOVA or Kruskal-Wallis, but also machine learning classification procedures, with support for SVM and LDA. Data reduction via PCA is a feature of each of these functions. Additional tools are provided to test for multivariate and univariate normality, homogeneity of covariance matrices and the presence of outliers. A permutation test of spatial autocorrelation within subsets is also available. But let's dive in with a worked out example.

```{r, include = FALSE}
library(nmgc)
data <- read.csv("data/reflectance.csv", header = TRUE)
```

The example dataset is highly multidimensional, and consists of reflectance spectrometry measurements taken on multiple individual lizards of the species *Anolis sagrei* throughout islands in the West Indies, and we are interested in detecting differences in coloration between different habitats (our `grouping` variable) within each island (our `nesting` variable). The measurements consist of reflectance scores across wavelengths from 300 to 700nm:

```{r, echo = FALSE}
data[1:3, c("island", "habitat", "wl300", "wl301", "wl302")]
```

Note that all functions can perform their analyses on non-nested datasets, if the `nesting` argument is unspecified. The output will be similar, albeit slightly different for some functions, but this is not the focus of this vignette.

# Machine learning classification analysis

We can use the `classify` function to train classifier machines to recognize patterns of differences between our groups in a multidimensional space. The function supports two types of classifiers: SVM and LDA.

## Support Vector Machines

We can train Support Vector Machines (SVM) to learn the differences in multivariate reflectance between lizards from different habitats, on each island separately, using:

```{r, message = FALSE}
variables <- paste0("wl", 300:700)
res_ml <- classify(
  data, variables = variables, grouping = "habitat", nesting = "island",
  method = "SVM", k = 5, nrep = 1, seed = 24, digest = FALSE     
)
```

This function splits the dataset into subsets, one for each island, and performs a classification analysis with k-fold cross-validation. That is, each subset is split into `k` bins at random, and each bin in turn is taken as a testing set, while the rest consists of a training set that will be used to train a classifier machine. The type of classifier is defined by `method`, and currently supports Linear Discriminant Analysis (LDA) and SVM. A k-value of 5 means that each machine is tested against 20% of the data that it was not fitted on. The procedure is repeated `nrep` times, so in the end, `k` times `nrep` machines will be trained. Increasing `nrep` will take more time but will correct for stochasticity, especially when the subsets are small. A `seed` can be provided to make the result reproducible. In this algorithm, the training sets are downsampled to the number of observations of the least represented group in the training set, to avoid biasing the classification. You can specify a `minsize` argument specifying the minimum number of observations that each group must have in the training set. Use `verbose` and `pb` to turn on and off messages and progress bars (useful when the analyses takes a while). 

The `classify` function returns a list of confusion matrices, representing the outcome of the classification test performed on each machine, i.e. the number of observations from the testing set classified into each group (in rows), versus the group they actually came from (in columns). The list is nested within each level of the nesting variable (here islands), and then within replicates and cross-validation bins. To access the confusion matrix of the first bin within the first replicate on the first island, use:

```{r}
res_ml[[1]][[1]][[1]]
```
The result also features fields `imp` and `machine`. Those will be filled if arguments `importance` and `return_machine` are set to TRUE, respectively. `importance` specifies to also perform a one-dimensional sensitivity analysis on the data (as implemented in the `Importance` function from the `rminer` package). This procedure evaluates, for each machine, how the classification output changes with changes in the input variables, and returns a vector of relative importance scores (which sum up to one) across input variables. But caution, this procedure makes the whole analysis a lot longer. The argument `return_machine` will return the actual fitted machine, which can then be re-used in further classification.

If the argument `digest` is TRUE, the function returns, instead of a nested list of confusion matrices, machines and importance vectors, a list of summaries of the classification analysis.

```{r}
res_ml_digest <- classify(
  data, variables = variables, grouping = "habitat", nesting = "island",
  method = "SVM", k = 5, nrep = 100, seed = 24, digest = TRUE     
)
```
The first summary is `mean`, a data frame showing the mean classification accuracy (how many observations were correctly classified during the testing of the machines), and, if `test` is TRUE (the default), the number of observation in each subset, the proportion of each subset used in testing as well as the number of observations in the testing set, and a binomial test's P-value assessing the significance of the deviation from the observed mean classification accuracy to that expected if a machine was guessing at random, given the number of observations in the testing set. 

```{r}
res_ml_digest$mean
```

The second summary, `avg`, is a list of average confusion matrices across machines (the average across replicates of the average across cross-validation bins), for each subset of the data. For example, here is the average confusion matrix on the first island:

```{r}
res_ml_digest$avg[[1]]
```

The third summary, `accu`, contains the distribution of accuracy scores of all machines for each subset (ideal for plotting histograms of classification accuracy):

```{r}
res_ml_digest$accu %>% head
```

The fourth summary, `confs`, is a nested list containing the confusion matrices of all machines, in a similar way to the `conf` element of the nested list returned by `classify` when `digest` is FALSE.

The fifth and last summary, `imp`, is a data frame recording the relative importance of each input variable measured across all machines, within each subset, and only if `importance` is TRUE. Again, beware that this setting is time-consuming.

## Linear Discriminant Analysis

The `classify` function supports SVM and LDA as its `method` argument. LDA analyses are typically faster than SVM, and the output is the same, so we do not show an example here.

## Plotting

We provide the `plot_classif` function to plot the output of `classify`. It is designed to work with classifications for which `digest` was set to TRUE, and contains lots of graphical parameters to tweak. The main layer on the plot is a histogram of classification accuracies. Other layers can be added. If `add_insets` is TRUE, average confusion matrices can be added as an inset plot. If `add_null` is TRUE, a dashed line is drawn showing the density of a corresponding binomial distribution, which is the expected distribution of classification accuracy under random guessing. If `add_pvalues` is TRUE, binomial test P-values are added to the plots. See `?plot_classif` for more information about the graphical parameters. If `type` is "confusion", then only average confusion matrices and no histograms are plotted.

```{r, message = FALSE}
plot_classif(res_ml_digest, facets = "island")
```

# Dimensionality reduction

Here is a good time to mention that most analysis functions in this package support dimensionality reduction using Principal Component Analysis (PCA) prior to perform the actual analysis. If the analysis is nested, e.g. within islands, then a PCA can be performed within each subset separately. For example, to perform a SVM-classification on the first four principal components of a PCA-reduced dataset, use:

```{r}
res_ml_pca <- classify(
  data, variables = paste0("PC", 1:4), grouping = "habitat", nesting = "island",
  method = "SVM", k = 5, nrep = 1, seed = 24, to_pcomp = paste0("wl", 300:700)
)
```

This will perform, within each island, a PCA on all 400 reflectance variables from 300 to 700nm, and retain the first four, which probably explain most of the variance. The `variables` analyzed are now the principal components, while the variables used to perform the PCA are provided in `to_pcomp`. Reducing the data with PCA may greatly reduce the time needed to perform the analysis. The results are returned as described in the previous sections.

In the backgroud, PCA-reduction is done using the function `npcomp` (which stands for "nested" principal component). This function performs PCA within each specified subset (or reduces to base R's `prcomp` if `nesting` is unspecified), and is used as follows:

```{r}
pca <- npcomp(
  data, variables = paste0("wl", 300:700), nesting = "island", 
  combine = TRUE, reduce = 1:4
)
```

If `combine` is FALSE, the function will return a list of multiple `prcomp` outputs, one for each subset. If `combine` is TRUE, it will return a summarized version of the multiple PCAs performed. In this case, the argument `reduce` indicates which principal components to retain from each subset before combining them all together.

The combined output is a list of multiple elements. The first element, `sdev`, is a data frame summarizing the proportion of the variance explained by each PC within each subset.

```{r}
pca$sdev
```

The second element, `rotation`, is a data frame consisting of the rotation matrices (as computed in `prcomp`) for each subset, stacked on top of each other.

```{r}
pca$rotation %>% head
```

The third element, `x`, is a data frame with the scores of each observation on each PC, for each subset. 

```{r}
pca$x %>% head
```

# Analyses of Variance

## Univariate OLS and GLS-ANOVA

To perform more classical group comparison analyses, use the `nanova` function (which stands for "nested" ANOVA). Same as for `classify`, `nanova` takes a `to_pcomp` argument that allows it to work on PCA-reduced data. The `nanova` function can be used to perform multiple univariate ANOVAs, within each subset (if `nesting` is specified), along each of the specified `variables`. However, because the use of regular, Ordinary Least Squares (OLS) ANOVA is ill-advised when the variance is heterogeneous across groups (heteroskedasticity), this function uses a Generalized Least Squares (GLS) algorithm (function `gls` from the `nlme` package), which accounts for heterogeneity of variances across groups by estimating one residual variance per group. To avoid overfitting, the goodness-of-fit of each ANOVA is compared between its OLS and GLS version using AICc (from package `MuMIn`), and the results of the best fitting approach are returned (lowest AICc). The function is used as follows:

```{r, message = FALSE}
res_anova <- nanova(
  data, variables = paste0("PC", 1:4), to_pcomp = paste0("wl", 300:700), 
  grouping = "habitat", nesting = "island", assumptions = TRUE, posthoc = TRUE
)
```

The results for each variable within each subset are returned in the form of a data frame showing the best-fitting model (OLS or GLS), where the P-values for the effect of the group-term are computed using a Likelihood Ratio Test on Maximum Likelihood-fitted models. Post-hoc multiple comparisons can be performed if the argument `posthoc` is TRUE, and one column is added for each contrast to be tested, featuring its respective P-value. Tukey's HSD test is used for post-hoc comparisons if the OLS-model was the best fit, however, if the assumption of homoskedasticity was violated and the GLS-model had the best fit, then Wilcoxon's test is used.

```{r}
res_anova$anova %>% head
```

Note that if `assumptions` is TRUE, the function will also return a list of results of tests of assumptions of the (multivariate) analysis of variance, named `assum`. The first element of this list is `multinorm`, the results of multiple Henze-Zirkler's tests of multivariate normality within each group in each subset, if `univariate` is FALSE, or the results of multiple Shapiro-Wilk's tests on each variable within each group in each subset, if `univariate` is TRUE. For example, here: 

```{r}
res_anova$assum$multinorm %>% head
```

The second element of `assum` is `cov`, a data frame with the results of Box's M-tets of homogeneity of covariance matrices across groups, performed within each subset.

```{r}
res_anova$assum$cov
```

The last element in `assum` in `outliers`, a nested list of identified multivariate outliers within each group and each subset, found using the Mahalanobis distance. 

For more information on the assumption-testing functions, see `?test_multinorm`, `?test_covariance` and `?test_outliers` for each of these three outputs, respectively.

## MANOVA

The `nanova` function also implements the Multivariate Analysis of Variance (MANOVA). For this, set the `manova` argument to TRUE:

```{r}
res_manova <- nanova(
  data, paste0("PC", 1:4), to_pcomp = paste0("wl", 300:700), grouping = "habitat",
  nesting = "island", manova = TRUE, test = "Wilks", assumptions = FALSE
)
```

The `test` argument specifies the statistics used in the MANOVA, and can be either of those accepted in base R's `manova` function (the default is Pillai's trace). The results look like this:

```{r}
res_manova
```

## Kruskal-Wallis tests

You may want to repeat some analyses on specific subsets or variables that violate the assumptions of the aforementioned models, using nonparametric Kruskal-Wallis comparisons. You can do this with `nanova`, by setting `kw` to TRUE:

```{r}
res_kw <- nanova(
  data, paste0("PC", 1:4), to_pcomp = paste0("wl", 300:700), grouping = "habitat",
  nesting = "island", kw = TRUE, assumptions = FALSE
)
res_kw %>% head
```
For now, multiple post-hoc comparisons are not implemented for the Kruskal-Wallis tests, and are only done when univariate OLS/GLS ANOVAs are performed. I may change this in a further release, allowing e.g. to use Wilcoxon posthoc tests when performing Kruskal-Wallis tests.

# Spatial autocorrelation

Nested datasets spanning multiple islands, for example, often consist in a few sampling sites within each island. And often, those sampling sites are too few for checking for spatial autocorrelation using sites, and their multivariate means in the variables measured, as observation units in traditional Mantel's or Moran's I tests. One way to still test for spatial autocorrelation within islands, or subsets, when only a few sampling sites are present is to use individual observations as units and randmly shuffle them across sites many times, re-estimating the correlation between multivariate means of the sites and their geographical distances every time, to produce a null distribution. Such a permutation test is implemented in the function `nspcortest`, and can be used as follows:

```{r, message = FALSE}
res_cortest <- nspcortest(
  data, variables = paste0("PC", 1:4), to_pcomp = paste0("wl", 300:700),
  nesting = "island", nperm = 10, seed = 24, lon = "longitude", lat = "latitude"
)
```

Here, the `lon` and `lat` argument specify the columns containing the longitude and latitude information, which must be present in the dataset for every individual. `nperm` must be high enough for the null distribution of spatial correlation coefficients to be meaningful (here it is too low, just for the sake of the example). The `see` can be reset to make the result reproducible. The results look like this:

```{r}
res_cortest$res
```

where `robs` is the measured Pearson's correlation coefficient between the Euclidean distances among the sites, within each subset, in multivariate variable-space, and the geodesic geographic distances among the sites at the surface of the Earth (computed using the `geosphere` package). The P-values indicate the proportion of the `nperm` permuted data had a spatial correlation coefficient higher than the one observed on the actual data. The number of sites for each subset is also returned.

In addition, the function returns a data frame showing the multivariate means and geographical coordinates of each site within each subset:

```{r}
res_cortest$sites %>% head
```

We hope you enjoy using this package!
